{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 线性回归（概念重要，但浅尝辄止即可）\n",
    "\n",
    "线性回归输出是一个连续值，因此适用于回归问题。回归问题在实际中很常见，如预测房屋价格、气温、销售额等连续值的问题。与回归问题不同，分类问题中模型的最终输出是一个离散值。我们所说的图像分类、垃圾邮件识别、疾病检测等输出为离散值的问题都属于分类问题的范畴。softmax回归则适用于分类问题。\n",
    "\n",
    "由于线性回归和softmax回归都是单层神经网络，它们涉及的概念和技术同样适用于大多数的深度学习模型。我们首先以线性回归为例，介绍大多数深度学习模型的基本要素和表示方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.1 线性回归的基本要素\n",
    "---\n",
    "\n",
    "3.1.1 线性回归的基本要素\n",
    "\n",
    "    3.1.1.1 模型定义\n",
    "    3.1.1.2 模型训练\n",
    "        (1) 训练数据\n",
    "        (2) 损失函数\n",
    "        (3) 优化算法\n",
    "    3.1.1.3 模型预测\n",
    "    \n",
    "\n",
    "篇幅有限，参见原文的讲解。\n",
    "https://trickygo.github.io/Dive-into-DL-TensorFlow2.0/#/chapter03_DL-basics/3.1_linear-regression?id=_311-%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e7%9a%84%e5%9f%ba%e6%9c%ac%e8%a6%81%e7%b4%a0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.2 线性回归的表示方法\n",
    "---\n",
    "我们已经阐述了线性回归的模型表达式、训练和预测。下面我们解释线性回归与神经网络的联系，以及线性回归的矢量计算表达式。\n",
    "\n",
    "\n",
    "3.1.2 线性回归的表示方法\n",
    "\n",
    "    3.1.2.1 神经网络图\n",
    "    3.1.2.2 矢量计算表达式\n",
    "    \n",
    "篇幅有限，参见原文的讲解。\n",
    "https://trickygo.github.io/Dive-into-DL-TensorFlow2.0/#/chapter03_DL-basics/3.1_linear-regression?id=_311-%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e7%9a%84%e5%9f%ba%e6%9c%ac%e8%a6%81%e7%b4%a0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3.1.2.2 矢量计算表达式\n",
    "\n",
    "两个向量相加的两种方法。 第一种，两个向量按元素逐一做标量加法；第二种，两个向量直接做矢量加法。\n",
    "\n",
    "简单说：for loop vs. 向量化计算\n",
    "\n",
    "矢量加法更好，下面来验证一下 c:=a+b："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for loop:0.23195791244506836\n",
      " vectors:0.0003609657287597656\n"
     ]
    }
   ],
   "source": [
    "# 1.定义两个向量\n",
    "\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "\n",
    "a = tf.ones((1000,))\n",
    "b = tf.ones((1000,))\n",
    "\n",
    "c = tf.Variable(tf.zeros((1000,)))\n",
    "\n",
    "\n",
    "# 2.1 按元素逐一做标量加法(for loop)\n",
    "\n",
    "tic = time()\n",
    "for i in range(1000):\n",
    "    c[i].assign(a[i]+b[i])\n",
    "toc = time()\n",
    "print(\"for loop:\"+str(toc-tic))\n",
    "\n",
    "# 2.2 矢量加法（向量化计算）\n",
    "\n",
    "tic = time()\n",
    "c.assign(a+b)\n",
    "toc = time()\n",
    "print(\" vectors:\"+str(toc-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "小结\n",
    "---\n",
    "- 和大多数深度学习模型一样，对于线性回归这样一种单层神经网络，它的基本要素包括模型、训练数据、损失函数和优化算法。\n",
    "- 既可以用神经网络图表示线性回归，又可以用矢量计算表示该模型。\n",
    "- 应该尽可能采用矢量计算，以提升计算效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
